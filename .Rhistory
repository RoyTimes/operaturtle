# Find an appropriate endpoint to query for statistics about a particular repo,
# and use it to get a list of contributors to the `tidyverse/dplyr` repository.
# Who were the top 10 contributor in terms of number of total commits?
# NOTE: This will be a really big response with lots of data!
# Exercise 1: reading and querying a web API
# Load the httr and jsonlite libraries for accessing data
# You can also load `dplyr` if you wish to use it
library(httr)
library(jsonlite)
library(dplyr)
# Create a variable for the API's base URI (https://api.github.com)
base_uri <- "https://api.github.com"
# Under the "Repositories" category, find the endpoint that will list repos in
# an organization
# Create a variable `resource` that represents the endpoint for the book
# organization (you can use `paste0()` to construct this, or enter it manually)
resource <- paste0("/users/", "info201", "/repos")
uri <- paste0(base_uri, resource)
# Send a GET request to this endpoint (the base.uri followed by the resource)
# and extract the response body
get_uri <- GET(uri)
# Convert the body from JSON into a data frame
body <- content(get_uri, "text")
body <- fromJSON(body)
#View(body)
# How many (public) repositories does the organization have?
public <- select(body,private) %>%
filter(private == FALSE) %>%
count(private) #summarize(n = n())
# Use a "Search" endpoint to search for repositories about "visualization" whose
# language includes "R"
# Reassign the `resource` variable to refer to the appropriate resource.
resource <- paste0(uri,"/search/","info201", "/?q=R")
# You will need to specify some query parameters. Create a `query_params` list
# variable that specifies an appropriate key and value for the search term and
# the language
query_params <- list(q = "q=language:r", sort = "forks")
# Send a GET request to this endpoint--including your params list as the `query`.
# Extract the response body and convert it from JSON.
response <- GET(resource, query = query_params)
response
bd <- content(response, "text")
bd <- fromJSON(bd)
# How many search repos did your search find? (Hint: check the list names)
# What are the full names of the top 5 results?
# Use the API to determine the number of people following Hadly Wickham
# (`hadley`, the author of dplyr, ggplot2, and other libraries we'll be using).
# Find an appropriate endpoint to query for statistics about a particular repo,
# and use it to get a list of contributors to the `tidyverse/dplyr` repository.
# Who were the top 10 contributor in terms of number of total commits?
# NOTE: This will be a really big response with lots of data!
# Exercise 1: reading and querying a web API
# Load the httr and jsonlite libraries for accessing data
# You can also load `dplyr` if you wish to use it
library(httr)
library(jsonlite)
library(dplyr)
# Create a variable for the API's base URI (https://api.github.com)
base_uri <- "https://api.github.com"
# Under the "Repositories" category, find the endpoint that will list repos in
# an organization
# Create a variable `resource` that represents the endpoint for the book
# organization (you can use `paste0()` to construct this, or enter it manually)
resource <- paste0("/users/", "info201", "/repos")
uri <- paste0(base_uri, resource)
# Send a GET request to this endpoint (the base.uri followed by the resource)
# and extract the response body
get_uri <- GET(uri)
# Convert the body from JSON into a data frame
body <- content(get_uri, "text")
body <- fromJSON(body)
#View(body)
# How many (public) repositories does the organization have?
public <- select(body,private) %>%
filter(private == FALSE) %>%
count(private) #summarize(n = n())
# Use a "Search" endpoint to search for repositories about "visualization" whose
# language includes "R"
# Reassign the `resource` variable to refer to the appropriate resource.
resource <- paste0(uri,"/search/repositories")
# You will need to specify some query parameters. Create a `query_params` list
# variable that specifies an appropriate key and value for the search term and
# the language
query_params <- list(q = "tetris+language:assembly", sort = "forks")
# Send a GET request to this endpoint--including your params list as the `query`.
# Extract the response body and convert it from JSON.
response <- GET(resource, query = query_params)
response
bd <- content(response, "text")
bd <- fromJSON(bd)
# How many search repos did your search find? (Hint: check the list names)
# What are the full names of the top 5 results?
# Use the API to determine the number of people following Hadly Wickham
# (`hadley`, the author of dplyr, ggplot2, and other libraries we'll be using).
# Find an appropriate endpoint to query for statistics about a particular repo,
# and use it to get a list of contributors to the `tidyverse/dplyr` repository.
# Who were the top 10 contributor in terms of number of total commits?
# NOTE: This will be a really big response with lots of data!
# Exercise 2: working with data APIs
# load relevant libraries
library(httr)
library(jsonlite)
library(dplyr)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
move_name <- "Bee Movie"
base_uri <- "https://api.nytimes.com/svc/movies/v2/"
resource <- "reviews/search.json"
query_params <- list(query = movie_name, "api-key" = nyt_key)
repsonse <- GET(paste0(base_uri, resource), query = query_params)
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# What kind of data structure did this produce? A data frame? A list?
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Flatten the movie reviews content into a data structure called `reviews`
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Create a list of the three pieces of information from above.
# Print out the list.
# Exercise 2: working with data APIs
# load relevant libraries
library(httr)
library(jsonlite)
library(dplyr)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
move_name <- "Bee Movie"
base_uri <- "https://api.nytimes.com/svc/movies/v2/"
resource <- "reviews/search.json"
query_params <- list(query = movie_name, "api-key" = nyt_key)
repsonse <- GET(paste0(base_uri, resource), query = query_params)
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# What kind of data structure did this produce? A data frame? A list?
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Flatten the movie reviews content into a data structure called `reviews`
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Create a list of the three pieces of information from above.
# Print out the list.
# Exercise 2: working with data APIs
# load relevant libraries
library(httr)
library(jsonlite)
library(dplyr)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
move_name <- "Bee Movie"
base_uri <- "https://api.nytimes.com/svc/movies/v2/"
resource <- "reviews/search.json"
query_params <- list(query = movie_name, "api-key" = nyt_key)
repsonse <- GET(paste0(base_uri, resource), query = query_params)
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# What kind of data structure did this produce? A data frame? A list?
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Flatten the movie reviews content into a data structure called `reviews`
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Create a list of the three pieces of information from above.
# Print out the list.
# Exercise 2: working with data APIs
# load relevant libraries
library(httr)
library(jsonlite)
library(dplyr)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
move_name <- "Bee Movie"
base_uri <- "https://api.nytimes.com/svc/movies/v2/"
resource <- "reviews/search.json"
query_params <- list(query = movie_name, "api-key" = nyt_key)
repsonse <- GET(paste0(base_uri, resource), query = query_params)
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# What kind of data structure did this produce? A data frame? A list?
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Flatten the movie reviews content into a data structure called `reviews`
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Create a list of the three pieces of information from above.
# Print out the list.
# Exercise 2: working with data APIs
# load relevant libraries
library(httr)
library(jsonlite)
library(dplyr)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
move_name <- "Bee Movie"
base_uri <- "https://api.nytimes.com/svc/movies/v2/"
resource <- "reviews/search.json"
query_params <- list(query = movie_name, "api-key" = nyt_key)
repsonse <- GET(paste0(base_uri, resource), query = query_params)
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# What kind of data structure did this produce? A data frame? A list?
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Flatten the movie reviews content into a data structure called `reviews`
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Create a list of the three pieces of information from above.
# Print out the list.
# Exercise 2: working with data APIs
# load relevant libraries
library(httr)
library(jsonlite)
library(dplyr)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
move_name <- "Bee Movie"
base_uri <- "https://api.nytimes.com/svc/movies/v2/"
resource <- "reviews/search.json"
query_params <- list(query = movie_name, "api-key" = nyt_key)
repsonse <- GET(paste0(base_uri, resource), query = query_params)
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# What kind of data structure did this produce? A data frame? A list?
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Flatten the movie reviews content into a data structure called `reviews`
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Create a list of the three pieces of information from above.
# Print out the list.
# Exercise 2: working with data APIs
# load relevant libraries
library(httr)
library(jsonlite)
library(dplyr)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
#move_name <- "Bee Movie"
#base_uri <- "https://api.nytimes.com/svc/movies/v2/"
#resource <- "reviews/search.json"
#query_params <- list(query = movie_name, "api-key" = nyt_key)
#repsonse <- GET(paste0(base_uri, resource), query = query_params)
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# What kind of data structure did this produce? A data frame? A list?
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Flatten the movie reviews content into a data structure called `reviews`
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Create a list of the three pieces of information from above.
# Print out the list.
install.packages("ggplot2")
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_wrap(~class)
library(ggplot2)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_wrap(~class)
# Alternatively, install "tidyverse"
install.packages("tidyr")  # once per machine
library(ggplot2)
# Alternatively, install "tidyverse"
library("tidyr")
# Make a data.frame (example)
students <- data.frame(
name = c('Mason', 'Tabi', 'Bryce', 'Ada', 'Bob','Filipe'),
section = c('a','a','a','b','b','b'),
math_exam1 = c(91, 82, 93, 100, 78, 91),
math_exam2 = c(88, 79, 77, 99, 88, 93),
spanish_exam1 = c(79, 88, 92, 83, 87, 77),
spanish_exam2 = c(99, 92, 92, 82, 85, 95)
)
View(students)
library(shiny)
my_ui <- fluidPage(
# A widget: a text input box (save input in the `username` key)
textInput("username", label = "What is your name?"),
# An output element: a text output (for the `message` key)
textOutput("message")
)
View(my_ui)
library(shiny)
my_ui <- fluidPage(
# A widget: a text input box (save input in the `username` key)
textInput("username", label = "What is your name?"),
# An output element: a text output (for the `message` key)
textOutput("message")
)
my_server <- function(input, output) {
# assign a value to the `message` key in `output`
# argument is a reactive expression for showing text
output$message <- renderText({
# use the `username` key from input and and return new value
# for the `message` key in output
return(paste("Hello", input$username))
})
}
shinyApp(ui = my_ui, server = my_server)
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
library(shiny)
shinyApp(ui, server)
library(shiny)
shinyApp(my_ui, my_server)
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
runApp('GitHub/a8-data-app-snwdrft')
shiny::runApp('GitHub/operaturtle')
ggimage(img, fullpage = FALSE, scale_axes = TRUE) +
geom_tile()
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggmap)
library(jpeg)
library(data.table)
img <- readJPEG("data/erangel.jpg")
setwd("~/GitHub/operaturtle")
data.in <- read.csv("data/output.csv")
img <- readJPEG("data/erangel.jpg")
data.players <- data.frame("Player" = paste0("Player: ", c(0:99)))
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x)
data.y <- select(data.in, contains("y")) %>%
select(contains("victim")) %>%
gather(Player, Y, deaths_0_victim_position_y:deaths_9_victim_position_y)
data.time <- select(data.in, contains("time")) %>%
gather(Player, Time, deaths_0_time_event:deaths_9_time_event)
data.weapon <- select(data.in, contains("description")) %>%
gather(Player, Weapon, deaths_10_description:deaths_9_description)
data.map <- data.frame(data.x, data.y, data.time)
data.ratio <- mutate(data.x, lat = X / 10000)
ggimage(img, fullpage = FALSE, scale_axes = TRUE) +
geom_tile()
heatmap
heatmap <- ggplot(data.map, aes(x = X, y = Y, fill = Time)) +
ggimage(img, fullpage = FALSE, scale_axes = TRUE) +
geom_tile()
heatmap
data.ratio <- mutate(data.x, max = max(X))
View(data.ratio)
x.max <- data.x[ ,max(data.x$X)]
x.max <- max.col(data.x)
x.max <- max.col(data.x$X)
View(x.max)
x.max <- max(data.x$X)
View(x.max)
x.max <- summarise(data.x, max(X))
View(x.max)
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(Lat = max(X, na.rm=TRUE))
View(data.x)
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(Lat = (X - min(X, na.rm=TRUE)))/ ((max(X, na.rm=TRUE) - min(X, na.rm=TRUE)))
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(Lat = X / max(X, na.rm=TRUE))
View(data.max)
View(data.x)
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(Lat = X / max(X, na.rm=TRUE)) %>%
select(-X)
View(data.x)
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(X = X / max(X, na.rm=TRUE))
View(data.x)
data.y <- select(data.in, contains("y")) %>%
select(contains("victim")) %>%
gather(Player, Y, deaths_0_victim_position_y:deaths_9_victim_position_y) %>%
mutate(Y = Y / max(Y, na.rm=TRUE))
data.time <- select(data.in, contains("time")) %>%
gather(Player, Time, deaths_0_time_event:deaths_9_time_event) %>%
mutate(Time = Time / max(Time, na.rm=TRUE))
data.time <- select(data.in, contains("time")) %>%
gather(Player, Time, deaths_0_time_event:deaths_9_time_event) %>%
mutate(Time = Time / max(Time, na.rm=TRUE))
data.map <- data.frame(data.x, data.y, data.time)
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(Lat = (X-min(X))/(max(X)-min(X)))
View(data.x)
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(Lat = (X-min(X, na.rm=TRUE))/(max(X, na.rm=TRUE)-min(X, na.rm=TRUE)))
View(data.x)
data.x <- select(data.in, contains("x")) %>%
select(contains("victim")) %>%
gather(Player, X, deaths_0_victim_position_x:deaths_9_victim_position_x) %>%
mutate(X = (X - min(X, na.rm=TRUE)) / (max(X, na.rm=TRUE) - min(X, na.rm=TRUE)))
View(data.x)
data.y <- select(data.in, contains("y")) %>%
select(contains("victim")) %>%
gather(Player, Y, deaths_0_victim_position_y:deaths_9_victim_position_y) %>%
mutate(Y = (Y - min(Y, na.rm=TRUE)) / (max(Y, na.rm=TRUE) - min(Y, na.rm=TRUE)))
data.time <- select(data.in, contains("time")) %>%
gather(Player, Time, deaths_0_time_event:deaths_9_time_event) %>%
mutate(Time = (Time - min(Time, na.rm=TRUE)) / (max(Time, na.rm=TRUE) - min(Time, na.rm=TRUE)))
data.map <- data.frame(data.x, data.y, data.time)
View(data.map)
heatmap <- ggplot(data.map, aes(x = X, y = Y, fill = Time)) +
ggimage(img, fullpage = FALSE, scale_axes = TRUE) +
geom_tile()
heatmap <- ggplot(data.map, aes(x = X, y = Y, fill = Time)) +
geom_tile()
heatmap
data.map <- data.frame(data.x, data.y, data.time)
